[experiment]
experiment_no = 0
robot_name = point_robot_env
logging = logging
ppo = my_ppo

[my_ppo]
env_maker = my_env_maker
vec_env_maker = my_vec_env_maker
network = mlp
total_timesteps = 1e6
lr = lambda f: 3.0e-4 *f
nsteps = 1024
log_interval = 1
value_network = copy
nminibatches = 32
noptepochs = 10
num_hidden = 64
num_layers = 2
seed = 0

[my_vec_env_maker]
type = shmem
nenvs = 10
normalize = False

[my_env_maker]
entrypoint = roam_rl.env.utils.env_maker:WrapObsEnvMaker
observation_wrapper = FlattenDictWrapper
env = my_robot_env

[my_robot_env]
entrypoint = roam_rl.robot_env:RobotEnv
robot_world = my_robot_world
state_sampler = my_state_sampler
max_episode_steps = 100


[my_robot_world]
entrypoint = roam_robot_worlds.robot_world:SimulatedRobotWorld
dynamics = roam_robot_worlds.simple_robots.point_numpy_robot:PointNumpyDynamics


[my_state_sampler]
entrypoint = roam_rl.robot_env.state_sampler:UniformStateSampler

[logging]
enable_detail_logging = False
env_base_log_level = 12
env_detail_log_level = 11
script_base_level = 12
script_detail_level = 11
script_debug_level = 10
script_console_level = 12