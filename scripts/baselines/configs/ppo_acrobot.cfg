[experiment]
experiment_no = 0
algo = my_ppo

[my_ppo]
entrypoint = roam_rl.baselines:PPO
env_maker = my_env_maker
vec_env_maker = my_vec_env_maker
network = my_network
total_timesteps = 1e6
lr = lambda f: 3.0e-4 *f
nsteps = 2048
log_interval = 1
value_network = copy
nminibatches = 4
noptepochs = 10

seed = 0

[my_network]
type = mlp
num_hidden = 64
num_layers = 4

# [my_network]
# type = lstm
# nlstm = 256
# layer_norm_lstm = True

# [my_network]
# type = mlp_lstm_mlp
# num_layers_in = 2
# num_hidden_in = 16
# nlstm = 256
# layer_norm_lstm = True

[my_vec_env_maker]
type = dummy
nenvs = 1
normalize_ret = True
normalize_obs = True

[my_env_maker]
entrypoint = roam_env.utils.env_maker:EnvMaker
env = my_robot_env

[my_robot_env]
id = Acrobot-v1
